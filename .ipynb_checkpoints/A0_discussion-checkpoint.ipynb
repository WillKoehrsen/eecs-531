{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Discussion\n",
    "## January 29, 2018\n",
    "### William Koehrsen wjk68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Difficulties\n",
    "\n",
    "Before we could begin our discussion, we had to solve a few technical issues. We were able to get everyone set up with git and all members of the group (those who were present) have now figured out how to make a commitment to the Case Engineering repository. The git workflow can be confusing at first, but once you have a little practice, it gets easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All members of our group will be using Python in Jupyter Notebooks. This is much simpler than the Matlab plus tex files arrangement and Python has great libraries for computer vision such as OpenCV and Keras. Jupyter and Python significantly reduces the set-up necessary and will allow us to spend more time solving problems. Moreover, there are some impressive new advances coming for Jupyter such as [Jupyter Lab](https://github.com/jupyterlab/jupyterlab) (where I am writing this now) and [Google Colaboratory](https://colab.research.google.com/notebook) which is online virtually hosted Jupyter Notebooks that can be shared like any other Google Drive file. This allows for real-time collaboration and provides plenty of compuatational resources for those who may not have access to capable machines locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best approach seems to be a supervised learning approach with some form of machine learning or deep learning. We have a standard template for the letter we want to identify, say \"h.\" We segment the input image into individual letters which we then hand code with labels (or have some undergrads do the work). We could do this for many images until we have thousands of letters labeled by whether or not they are the letter \"h.\" Then, we train our model, say a convolutional neural network, on the training data by giving it both the training images (individual letters) and the labels (\"h\" or not). A convolutional neural network would be ideal for this task with a sequence of 2-d convolutional layers followed by max pooling. The output from the convolutional layers would then be flatted to a single dimension and fed through a few fully connected layers. The output layer of the network would have a sigmoid activation function to turn the logits into probabilities of whether or not the input letter was an h. The final output will be a probability of the letter being h that can be compared to the actual known label. \n",
    "\n",
    "The loss for the network would be binary cross entropy because the label can only take on two values and the optimization function could be the Adam optimizer with a small learning rate. Using backprop, the model will adjust the weights to reduce the loss on the training data. We would run the model through all the images a few hundred times (depending on our computational resources) or until the cross validation loss begins to increase (we would use early stopping). Then, we would test on model on testing data, which would be more individual letters but without the corresponding labels. If the model performs poorly we could then get more training data, use data augmentation techniques, make the network deeper, or change the network architecture by using methods like residual connections and batch norm. After we had optimized our model, we would test it again and see the performance. This is not a difficult task and the model should achieve high accuracy given how well even simple neural networks perform on tasks such as MNIST. The deep learning approach may even be more than is needed for the letter identification, and traditional machine learning methods such as random forest or gradient boosting could solve the problem using labeled training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One member of our group works with robotics and has experience using thermal imaging to identify living creatures. The next step is object identification and segmentation which would be a good project for this class. I do not have any image data, but there is plenty available online. I would like to compete in the [Kaggle 2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018) which this year is about finding nuclei in divergent cells. I would approach this using convolutional neural networks using [Keras](https://keras.io/) which is built on top of [TensorFlow](https://www.tensorflow.org/tutorials/deep_cnn). There are many techniques that could be practiced with this competition including convolutional neural networks, data augmentation, and using parallel processing (GPUs) to train models. I think this would be a good team project and would be a great chance to learn from the community. Competitions such as Image Net ([ILSVRC])(http://www.image-net.org/challenges/LSVRC/) have driven the computer vision field, and they are wonderful opportunities to get practice on challenges and receive feedback from the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
